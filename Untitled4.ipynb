{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c60b1408",
   "metadata": {},
   "source": [
    "Let's break down the core concepts of hypothesis testing, focusing on the null and alternative hypotheses, as well as the examples you've provided (e.g., presidential comparisons):\n",
    "\n",
    "### 1. **What is a Hypothesis?**\n",
    "In the context of statistics, a **hypothesis** is a claim or assumption that we want to test. Hypothesis testing is a formal process used to determine if there is enough evidence in a sample of data to infer that a certain condition is true for the entire population.\n",
    "\n",
    "### 2. **Null Hypothesis (H₀):**\n",
    "The **null hypothesis** is a statement that assumes **no effect** or **no difference**. It's the hypothesis that we try to disprove or reject in hypothesis testing. We assume the null hypothesis is true unless there is significant evidence against it.\n",
    "\n",
    "- Example: If we were testing whether there is a difference in presidential performance between Obama and Bush, the null hypothesis would be that there is **no difference** in their performance.\n",
    "\n",
    "  - **H₀:** Obama’s performance = Bush’s performance\n",
    "\n",
    "### 3. **Alternative Hypothesis (H₁ or Ha):**\n",
    "The **alternative hypothesis** is what you want to prove. It contradicts the null hypothesis and represents a new claim based on your data or research.\n",
    "\n",
    "- Continuing the presidential example:\n",
    "  - **H₁:** Obama’s performance ≠ Bush’s performance (This is a two-sided test, which can be \"greater than\" or \"less than,\" depending on the context.)\n",
    "\n",
    "### 4. **Decision Making in Hypothesis Testing:**\n",
    "Once you collect data, you conduct a statistical test to determine whether the evidence is strong enough to reject the null hypothesis. This decision is based on a probability threshold known as the **significance level (α)**, often set at 0.05.\n",
    "\n",
    "- If the evidence is strong enough (p-value < α), you **reject the null hypothesis** in favor of the alternative.\n",
    "- If the evidence is weak (p-value > α), you **fail to reject the null hypothesis**. Importantly, you don’t **accept** the null hypothesis; you simply conclude that there is not enough evidence to reject it.\n",
    "\n",
    "### 5. **Common Mistakes in Hypothesis Testing:**\n",
    "   - **\"We accept the null hypothesis\"**: Technically, this is incorrect. We don't \"accept\" the null; we say that we \"fail to reject\" it. The evidence wasn’t strong enough to refute it, but it doesn’t necessarily prove the null hypothesis is true.\n",
    "   - **Specification of the Null Hypothesis**: The null hypothesis is usually written with equality, such as “less than or equal to,” because hypothesis testing examines the possibility of equality or no effect.\n",
    "\n",
    "### 6. **Applying Hypothesis Testing to Presidential Comparisons:**\n",
    "In your examples:\n",
    "- **Hillary vs. Trump (before either became president)**: A hypothesis test comparing their presidential performance at the time of the election wouldn't make sense because neither had any data (experience as president) to base a performance comparison on. This would be an instance where you can't perform a meaningful hypothesis test.\n",
    "\n",
    "- **Obama vs. Bush**: This comparison is valid because both have served full terms, so you can gather data (policies, economic performance, etc.) to compare their presidencies. A hypothesis test could be constructed to determine if there is a statistically significant difference in their performance.\n",
    "\n",
    "- **Biden vs. Trump (future performance)**: While we have four years of data on both Biden’s and Trump’s past presidential performances, we can't directly compare their **future** performance because we lack data on what hasn't happened yet. You might be able to use the past data to make predictions, but that's outside the strict framework of hypothesis testing, which relies on observed data.\n",
    "\n",
    "- **Biden vs. Kamala Harris**: Hypothesis testing might help in predicting a Kamala Harris presidency based on the data from Biden’s presidency, but this would rely on assumptions and models, as Harris has not been president yet.\n",
    "\n",
    "### 7. **Key Takeaways:**\n",
    "- Hypothesis testing is used to assess whether there is enough evidence in a sample to reject a null hypothesis.\n",
    "- You cannot compare data that doesn't exist (such as future presidential performance), and you can only make meaningful comparisons based on existing data.\n",
    "- Hypothesis testing has specific conventions: we \"fail to reject\" the null, and the null hypothesis is typically written with equality.\n",
    "\n",
    "This should give you a clearer understanding of the distinction between null and alternative hypotheses, as well as how hypothesis testing applies to real-world examples like presidential comparisons."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9987c999",
   "metadata": {},
   "source": [
    "The p-value is a critical concept in hypothesis testing, and understanding it well is key to interpreting the results of statistical tests.\n",
    "\n",
    "### 1. **What is a p-value?**\n",
    "A **p-value** (probability value) is the probability of obtaining a test statistic as extreme or more extreme than the one observed in your sample data, **assuming the null hypothesis is true**. In simpler terms, it tells you how likely your data would occur if there is no effect or difference in the population.\n",
    "\n",
    "### 2. **How to Interpret a p-value:**\n",
    "   - **Low p-value (typically ≤ 0.05):** Strong evidence against the null hypothesis, so you reject the null hypothesis. This suggests that the observed data is unlikely to occur by chance if the null hypothesis is true.\n",
    "   - **High p-value (> 0.05):** Weak evidence against the null hypothesis, so you fail to reject the null hypothesis. This suggests that the data is consistent with the null hypothesis.\n",
    "\n",
    "### 3. **Technical Definition:**\n",
    "The formal definition of a p-value is \"the probability that a test statistic is as extreme or more extreme than the observed test statistic if the null hypothesis was true.\" Once you grasp this concept, it becomes an efficient and clear way to understand the strength of evidence in hypothesis testing.\n",
    "\n",
    "### 4. **Visualizing the p-value:**\n",
    "Imagine you have a bell curve (normal distribution) under the assumption that the null hypothesis is true. The test statistic from your data (e.g., a difference in means, a correlation coefficient) is a point on that curve. The p-value represents the area under the curve from that point to the tail of the distribution, essentially measuring how \"surprising\" your result is under the null hypothesis.\n",
    "\n",
    "### 5. **Common Misunderstandings:**\n",
    "   - A p-value **does not** tell you the probability that the null hypothesis is true. It simply tells you how unusual the data is, assuming the null hypothesis is true.\n",
    "   - A small p-value **does not** prove that the alternative hypothesis is true; it only provides evidence against the null hypothesis.\n",
    "\n",
    "### 6. **Connecting with Hypothesis Testing:**\n",
    "Once you calculate the p-value in a hypothesis test, you compare it with a pre-set significance level (α), typically 0.05:\n",
    "   - If the p-value is smaller than α, you reject the null hypothesis (the data provides sufficient evidence to support the alternative hypothesis).\n",
    "   - If the p-value is larger than α, you fail to reject the null hypothesis (the evidence isn't strong enough to rule out the null hypothesis).\n",
    "\n",
    "### Example:\n",
    "Imagine you're testing whether a coin is biased. The null hypothesis (H₀) is that the coin is fair. You flip the coin 100 times and observe 60 heads. A statistical test gives you a p-value of 0.04. This means that if the coin were fair, the probability of getting 60 heads or more in 100 flips is 4%. Since 0.04 is less than the common threshold of 0.05, you reject the null hypothesis and conclude that there is evidence to suggest the coin might be biased.\n",
    "\n",
    "### 7. **Key Takeaways:**\n",
    "- The p-value measures how likely your data would be if the null hypothesis were true.\n",
    "- A small p-value suggests that your data is unlikely under the null hypothesis and provides evidence for the alternative hypothesis.\n",
    "- Understanding the p-value allows you to make informed decisions in hypothesis testing quickly and effectively.\n",
    "\n",
    "Would you like more details or examples on interpreting p-values?\n",
    "yes,of crouse\n",
    "Let's dive deeper into p-values with more examples and details to clarify how they work and how to interpret them.\n",
    "\n",
    "### 1. **More on the p-value Concept:**\n",
    "The p-value helps you understand whether the observed data fits with the assumption of the null hypothesis. It’s a measure of how extreme the data is under this assumption. If the p-value is very low, it means the observed data is quite unlikely given the null hypothesis, prompting you to question whether the null hypothesis is true.\n",
    "\n",
    "### 2. **Visualizing the p-value:**\n",
    "Imagine a statistical distribution, like a normal distribution (a bell curve), where the peak represents the values most likely to occur under the null hypothesis. If your test statistic (e.g., difference in means, z-score, etc.) falls far from the center of this distribution (in the tails), the p-value will be small, indicating that the data is unusual under the null hypothesis.\n",
    "\n",
    "For example, in a two-sided test:\n",
    "- The center of the curve represents the situation where there is no difference (null hypothesis).\n",
    "- The farther your result is from the center (either on the left or right), the smaller the p-value, suggesting more evidence against the null hypothesis.\n",
    "\n",
    "### 3. **Interpreting Different p-values:**\n",
    "\n",
    "| **p-value**   | **Interpretation**                                                    |\n",
    "|---------------|-----------------------------------------------------------------------|\n",
    "| p ≤ 0.01      | **Very strong evidence** against the null hypothesis; reject H₀.      |\n",
    "| 0.01 < p ≤ 0.05 | **Moderate evidence** against the null hypothesis; reject H₀.        |\n",
    "| 0.05 < p ≤ 0.10| **Weak evidence** against the null hypothesis; consider further testing.|\n",
    "| p > 0.10      | **No evidence** against the null hypothesis; fail to reject H₀.       |\n",
    "\n",
    "### 4. **Examples of p-value Interpretation:**\n",
    "\n",
    "#### **Example 1: Testing a Drug’s Effectiveness**\n",
    "- **Null Hypothesis (H₀):** The drug has no effect on reducing symptoms (i.e., it works no better than a placebo).\n",
    "- **Alternative Hypothesis (H₁):** The drug has an effect on reducing symptoms.\n",
    "  \n",
    "After conducting a clinical trial, you calculate a p-value of **0.03**. Since this p-value is less than 0.05, you reject the null hypothesis. This suggests there is evidence to support the claim that the drug is effective, though it's not *extremely* strong evidence (which would require a p-value closer to 0).\n",
    "\n",
    "#### **Example 2: Coin Flip Fairness**\n",
    "- **Null Hypothesis (H₀):** The coin is fair (50% chance of heads, 50% chance of tails).\n",
    "- **Alternative Hypothesis (H₁):** The coin is biased (not a 50-50 distribution).\n",
    "\n",
    "You flip the coin 100 times and get 70 heads. The p-value of your test comes out to **0.001**. Since this p-value is very small, it suggests strong evidence against the null hypothesis, leading you to conclude the coin is likely biased.\n",
    "\n",
    "#### **Example 3: Testing for a Difference in Means (Two-sample t-test)**\n",
    "Suppose you want to test if there’s a difference in average scores between two groups of students (say, students who studied online vs. students who attended in-person classes).\n",
    "- **Null Hypothesis (H₀):** There is no difference in average scores between the two groups.\n",
    "- **Alternative Hypothesis (H₁):** There is a difference in average scores between the two groups.\n",
    "\n",
    "After performing a t-test, you calculate a p-value of **0.08**. Since this is greater than 0.05, you **fail to reject the null hypothesis**. This means there isn't strong enough evidence to conclude that the average scores differ between the two groups, but the evidence isn’t overwhelmingly in favor of the null either.\n",
    "\n",
    "### 5. **Key Points to Remember about p-values:**\n",
    "- **Significance Level (α):** The cutoff point you use to decide whether the p-value is small enough to reject the null hypothesis. A common value for α is 0.05, but it can be adjusted based on the field of study (e.g., 0.01 for more stringent tests).\n",
    "- **p-value is Not the Probability of the Null Hypothesis Being True:** A common misunderstanding is that the p-value tells you how likely the null hypothesis is true. Instead, it tells you how likely your data is under the assumption that the null hypothesis is true.\n",
    "- **Small p-value ≠ Important Effect:** A small p-value means the data doesn’t fit well with the null hypothesis, but it doesn’t necessarily mean that the effect size is large or important. Always consider practical significance alongside statistical significance.\n",
    "  \n",
    "### 6. **Common Misinterpretations of the p-value:**\n",
    "- **“A high p-value proves the null hypothesis is true.”** A high p-value only means that there isn’t enough evidence to reject the null hypothesis. It doesn’t prove that the null hypothesis is true.\n",
    "- **“A low p-value guarantees the alternative hypothesis is true.”** A low p-value suggests that the null hypothesis is unlikely, but it doesn’t confirm the alternative hypothesis. There could still be other explanations for the result.\n",
    "\n",
    "### 7. **Final Thought:**\n",
    "Understanding p-values allows you to make informed decisions about your hypothesis test results. It’s an elegant way of assessing how much evidence the data provides against the null hypothesis. Once you grasp this, reading and interpreting p-values becomes second nature and a powerful tool in statistical reasoning.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50972106",
   "metadata": {},
   "source": [
    "Here are concise explanations addressing the questions:\n",
    "\n",
    "### 1. **What is the key factor that makes the difference between ideas that can and cannot be tested statistically?**\n",
    "The key factor is **measurability**. An idea can be tested statistically if it can be expressed in a way that allows for data collection and measurable outcomes. In other words, the idea must be translated into something that can be quantified and analyzed using statistical methods.\n",
    "\n",
    "### 2. **What is the key criterion defining a good null hypothesis?**\n",
    "A good null hypothesis is **precisely defined, testable, and falsifiable**. It should represent a statement of no effect, no difference, or no relationship, making it something that can be tested using statistical analysis. It also needs to be clear and objective, without ambiguity, so that the results of the test can be interpreted properly.\n",
    "\n",
    "### 3. **What is the difference between a null hypothesis and an alternative hypothesis?**\n",
    "- The **null hypothesis (H₀)** is a statement that assumes no effect or no difference. It represents the default position that there is nothing new happening, and the observed data are the result of random chance.\n",
    "- The **alternative hypothesis (H₁ or Ha)** is the statement that contradicts the null hypothesis. It proposes that there is an effect, a difference, or a relationship. The goal of hypothesis testing is to determine if there is enough evidence to reject the null hypothesis in favor of the alternative hypothesis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16187a17",
   "metadata": {},
   "source": [
    "In simple terms, the distinction between the sample statistic (like the sample mean, denoted as \\( \\bar{x} \\)) and the population parameter (denoted as \\( \\mu \\)) is crucial in hypothesis testing. \n",
    "\n",
    "### Key Concepts:\n",
    "\n",
    "- **\\( x_i \\)**: These are individual data points in your sample (e.g., the scores or measurements you've collected).\n",
    "- **\\( \\bar{x} \\)**: This is the **sample mean**, which is the average value of your sample data. It is a statistic derived from the sample, not the entire population.\n",
    "- **\\( \\mu \\)**: This represents the **population mean**, the average value if you could measure the entire population. It's a parameter, a fixed value that we often don't know.\n",
    "- **\\( \\mu_0 \\)**: This is the **hypothesized population mean** under the null hypothesis. It's what you assume the population mean is, based on the null hypothesis.\n",
    "\n",
    "### The Difference Between Sample Statistic and Population Parameter:\n",
    "When conducting a hypothesis test, we calculate the **sample mean** from the data we’ve collected (since it’s typically impossible to measure an entire population). However, the goal is to make an inference about the **population mean**, which is the true average for the entire population. The hypothesis test helps us decide whether the sample mean \\( \\bar{x} \\) provides enough evidence to say that the population mean \\( \\mu \\) is different from the hypothesized value \\( \\mu_0 \\).\n",
    "\n",
    "### Explanation for a Non-Statistical Audience:\n",
    "In a test, we gather a sample of data (a smaller group) to make conclusions about the larger group (population). While the average of the sample (sample mean) is easy to compute, the hypothesis test helps us determine whether this sample average gives us enough evidence to say something meaningful about the true average for the entire group. \n",
    "\n",
    "In hypothesis testing, we focus on the population's true average (which is often unknown) rather than just the sample average, because our goal is to make statements about the entire group, not just the specific sample we collected.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61266f1f",
   "metadata": {},
   "source": [
    "When calculating a p-value, we **imagine a world where the null hypothesis is true** because we want to assess how likely our observed data (or something more extreme) is under that assumption. The idea is to determine if the data we collected could reasonably occur by chance if the null hypothesis holds.\n",
    "\n",
    "### Key Point:\n",
    "- **Sampling Distribution Under the Null Hypothesis**: When we assume the null hypothesis is true, we are essentially saying there is no real effect or difference. Based on this assumption, we know what the distribution of possible outcomes (test statistic values) should look like — this is called the **sampling distribution of the test statistic** under the null hypothesis. This distribution shows all the possible values our test statistic could take due to random variation alone.\n",
    "\n",
    "### Why We Do This:\n",
    "- By comparing our **observed test statistic** to this distribution, we can calculate the **p-value**, which tells us the probability of getting a test statistic as extreme as, or more extreme than, the one we observed if the null hypothesis is true. \n",
    "- If the p-value is very small, it means our observed result is quite unusual if the null hypothesis were true, giving us reason to **reject the null hypothesis**.\n",
    "- On the other hand, if the p-value is large, it suggests that our observed result could easily happen by random chance under the null hypothesis, so we **fail to reject the null hypothesis**.\n",
    "\n",
    "### Example Explanation:\n",
    "Imagine you're flipping a coin, and your null hypothesis is that it's a fair coin (50/50 chance of heads or tails). If you flip the coin 100 times and get 90 heads, you would calculate how likely it is to get 90 heads under the assumption the coin is fair (the null hypothesis). If that outcome is very unlikely (low p-value), you would start to doubt that the coin is fair and might reject the null hypothesis.\n",
    "\n",
    "In short, calculating the p-value based on a world where the null hypothesis is true allows us to measure how consistent our observed data is with the idea that \"nothing is happening\" (i.e., the null hypothesis is true). If the data is highly inconsistent with that world, we question the validity of the null hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f17a4b3a",
   "metadata": {},
   "source": [
    "To simulate a p-value for the Güntürkün (2003) study, where 80 out of 124 kissing couples tilted their heads to the right (64.5%), we'll use the **50/50 coin-flipping model**. The **null hypothesis** states that there is no preference for head tilting (i.e., the probability of tilting right or left is 50%). We will compute the probability of observing 80 or more couples tilting their heads to the right under the assumption of a 50/50 split (i.e., a fair coin flip for each couple's head tilt).\n",
    "\n",
    "### Steps to Simulate a P-value:\n",
    "\n",
    "1. **Null Hypothesis (H₀)**: The population has no head-tilt preference (50% tilt left, 50% tilt right).\n",
    "2. **Alternative Hypothesis (H₁)**: The population shows a preference for tilting heads to the right.\n",
    "3. **Simulate the Null Hypothesis**:\n",
    "    - In a world where the null hypothesis is true, each couple has a 50% chance of tilting right.\n",
    "    - Perform a large number of simulations (e.g., 10,000 coin flips) where each \"coin flip\" represents the tilt of one couple (right = heads, left = tails).\n",
    "    - Count how many times 80 or more couples out of 124 tilt their heads to the right in these simulations.\n",
    "4. **Calculate the P-value**:\n",
    "    - The p-value is the proportion of simulations where 80 or more couples tilt right. This tells us how likely it is to observe 80 out of 124 right tilts if there really is no preference (50/50).\n",
    "  \n",
    "### Simulating in Python:\n",
    "\n",
    "Let’s simulate this process and calculate the p-value. I will run a simulation using Python for you to estimate the p-value.\n",
    "\n",
    "\n",
    "\n",
    "The simulated p-value is approximately **0.001**. This means that, assuming there is no preference for tilting heads to the right (50/50 chance), the probability of observing 80 or more couples tilting right is about 0.1%.\n",
    "\n",
    "### Interpretation Using the Table:\n",
    "\n",
    "- A p-value of **0.001** falls under the category of **\"Very strong evidence against the null hypothesis.\"**\n",
    "\n",
    "This suggests that the observed 64.5% of couples tilting their heads to the right provides very strong evidence that there is indeed a preference for rightward head tilting during kissing, and the null hypothesis (no preference) can be rejected with high confidence.\n",
    "\n",
    "Let me know if you need further explanation!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "218a7c6f",
   "metadata": {},
   "source": [
    "No, a smaller p-value **cannot definitively prove** that the null hypothesis is false. A p-value simply tells us how likely our observed data is, assuming the null hypothesis is true. A very small p-value suggests that the observed data is unlikely under the null hypothesis, leading us to reject the null. However, it does not \"prove\" the null hypothesis is false — it only indicates strong evidence against it.\n",
    "\n",
    "### Regarding Fido (from the second pre-lecture video):\n",
    "- **Proving Innocence (Null Hypothesis True)**: A high p-value (close to 1) suggests that the data is consistent with the null hypothesis, but it does not **prove** Fido's innocence (or that the null hypothesis is true). We just say there is not enough evidence to reject the null hypothesis.\n",
    "- **Proving Guilt (Alternative Hypothesis True)**: A low p-value (e.g., less than 0.05) provides strong evidence against the null hypothesis, suggesting that Fido may be guilty (or that the alternative hypothesis is true). However, it doesn't definitively prove guilt; it just shows that the data is very unlikely if the null hypothesis were true.\n",
    "\n",
    "### Key Point:\n",
    "A p-value can never **prove** anything with absolute certainty. It only gives a measure of the strength of evidence against the null hypothesis. Even if the p-value is very small or very large, there is always some uncertainty due to randomness in data collection.\n",
    "\n",
    "In summary:\n",
    "- **No p-value** (whether high or low) can **definitively prove** guilt or innocence.\n",
    "- A low p-value gives strong evidence **against** the null hypothesis (suggesting guilt or an effect).\n",
    "- A high p-value suggests there is not enough evidence to reject the null (but doesn't prove innocence or the null's truth)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aed444e",
   "metadata": {},
   "outputs": [],
   "source": [
    "To adjust the code from \"Demo II of the Week 5 TUT\" to compute a p-value for a **one-sided (or one-tailed) hypothesis test**, we need to modify the approach in the following way:\n",
    "\n",
    "### Key Differences Between One-Sided and Two-Sided Tests:\n",
    "- **Two-Sided Test**: In a two-sided test, we check for extreme values in both directions (greater or smaller than the hypothesized value), meaning we're interested in deviations on both sides of the distribution.\n",
    "- **One-Sided Test**: In a one-sided test, we only check for extreme values in **one direction** (either greater than or less than the hypothesized value), focusing only on deviations in the specific direction of interest.\n",
    "\n",
    "### Steps to Adjust the Code:\n",
    "1. **Identify the direction** of the hypothesis test:\n",
    "   - For a **one-tailed test**, decide if you’re testing whether the observed statistic is **greater than** or **less than** the hypothesized value.\n",
    "   - For example, if you're testing whether the vaccine efficacy is greater than a certain threshold, this would be a **right-tailed** test.\n",
    "   \n",
    "2. **Modify the p-value calculation**:\n",
    "   - In a **two-tailed test**, the p-value is calculated by looking at both extremes of the distribution (left and right tails).\n",
    "   - In a **one-tailed test**, the p-value is based only on one tail of the distribution, which is either the left or right depending on the hypothesis.\n",
    "\n",
    "### Example Code Change:\n",
    "In a two-tailed test, the p-value is computed as:\n",
    "\n",
    "```python\n",
    "p_value = 2 * (1 - stats.norm.cdf(observed_statistic))\n",
    "```\n",
    "\n",
    "For a **one-tailed test**, if we're testing whether the observed statistic is **greater than** the hypothesized value (right-tailed test), the code becomes:\n",
    "\n",
    "```python\n",
    "p_value = 1 - stats.norm.cdf(observed_statistic)\n",
    "```\n",
    "\n",
    "Alternatively, for a **left-tailed test** (if we're testing whether the observed statistic is **less than** the hypothesized value), the code becomes:\n",
    "\n",
    "```python\n",
    "p_value = stats.norm.cdf(observed_statistic)\n",
    "```\n",
    "\n",
    "### How This Changes the Interpretation:\n",
    "- In a **one-tailed test**, you are only concerned with extreme values in **one direction** (e.g., if you believe that the observed effect can only be larger than the hypothesized value).\n",
    "- In contrast, a **two-tailed test** assumes you are open to extreme values on both sides (either larger or smaller than the hypothesized value).\n",
    "  \n",
    "Because of this, the **one-tailed p-value will usually be smaller** than the two-tailed p-value, as it only considers half of the distribution.\n",
    "\n",
    "### Should We Expect a Smaller P-value in a One-Tailed Test?\n",
    "Yes, the p-value for a **one-tailed test** will generally be **smaller** than for a two-tailed test, because:\n",
    "- In a two-tailed test, we are splitting the alpha level (usually 0.05) between both tails of the distribution, whereas in a one-tailed test, the entire alpha is applied to just one tail.\n",
    "- This makes it easier to reject the null hypothesis in the direction of the test because we are only focusing on one side of the distribution.\n",
    "\n",
    "Would you like me to help implement this in code using a specific example or walk through a detailed coding scenario?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f3f6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Here’s a structured approach to your report on Fisher's Tea Experiment, specifically tailored for your context of STA130 students.\n",
    "\n",
    "---\n",
    "\n",
    "### **Fisher's Tea Experiment Analysis**\n",
    "\n",
    "#### **1. Problem Introduction**\n",
    "In the realm of statistics, experiments often illuminate subtle differences in perception and preference. Ronald Fisher's experiment with Dr. Muriel Bristol is a classic tale of statistical inquiry, assessing whether the order of adding milk or tea significantly affects the taste. In this analysis, we conduct a similar experiment with 80 STA130 students, assessing their ability to discern the order in which tea and milk were added. \n",
    "\n",
    "#### **2. Relationship to Fisher and Bristol's Experiment**\n",
    "Fisher's original experiment involved Dr. Bristol’s personal preference regarding the order of milk and tea. While Bristol's results were striking—correctly identifying all 8 cups—our STA130 sample diverges in terms of sample size and the nature of the population. Instead of a unique individual's taste preference, we evaluate the broader question of whether students, as a group, can discern any difference purely by chance.\n",
    "\n",
    "#### **3. Statements of the Null Hypothesis and Alternative Hypothesis**\n",
    "- **Null Hypothesis (H₀)**: There is no difference in the ability of STA130 students to identify the order of milk and tea. Formally, this means the proportion of students who can correctly identify the order is equal to 0.5 (i.e., \\( p = 0.5 \\)).\n",
    "  \n",
    "  **Interpretive Statement**: We assume that students are just guessing and have no inherent ability to tell whether milk or tea was added first. \n",
    "\n",
    "- **Alternative Hypothesis (H₁)**: The ability of STA130 students to identify the order is greater than what would be expected by random guessing. Formally, this means \\( p > 0.5 \\).\n",
    "\n",
    "#### **4. Quantitative Analysis**\n",
    "In our study:\n",
    "- Sample size (n) = 80\n",
    "- Number of correct identifications (x) = 49\n",
    "\n",
    "The observed proportion of correct identifications is:\n",
    "\\[\n",
    "\\hat{p} = \\frac{x}{n} = \\frac{49}{80} = 0.6125\n",
    "\\]\n",
    "\n",
    "#### **5. Methodology Code and Explanations**\n",
    "To test our hypothesis, we will perform a simulation-based p-value calculation under the null hypothesis. We'll use Python for this simulation.\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "# Seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Parameters\n",
    "n = 80  # sample size\n",
    "observed_correct = 49  # number of correct identifications\n",
    "null_prob = 0.5  # probability under the null hypothesis\n",
    "\n",
    "# Simulation\n",
    "simulations = 10000  # number of simulations\n",
    "simulated_successes = np.random.binomial(n, null_prob, simulations)\n",
    "p_value = np.sum(simulated_successes >= observed_correct) / simulations\n",
    "\n",
    "# Output the p-value\n",
    "p_value\n",
    "```\n",
    "\n",
    "#### **(Optional) Supporting Visualizations**\n",
    "To visualize the simulation results and how our observed statistic compares to the null distribution, we can create a histogram:\n",
    "\n",
    "```python\n",
    "plt.hist(simulated_successes, bins=30, edgecolor='black', alpha=0.7)\n",
    "plt.axvline(observed_correct, color='red', linestyle='dashed', linewidth=2)\n",
    "plt.title('Distribution of Simulated Successes')\n",
    "plt.xlabel('Number of Correct Identifications')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "#### **6. Findings and Discussion**\n",
    "Upon running the simulation, we found a p-value of \\( p = \\) [insert p-value result]. \n",
    "\n",
    "- **Interpretation**: A low p-value (typically less than 0.05) would indicate that the results are statistically significant, suggesting that the observed success rate (49 out of 80) is unlikely to have occurred by random guessing. \n",
    "\n",
    "- If the p-value is high (greater than 0.05), we would fail to reject the null hypothesis, indicating no significant evidence that students can identify the order better than chance.\n",
    "\n",
    "#### **7. Conclusion Regarding the Null Hypothesis**\n",
    "Based on the computed p-value, we conclude that:\n",
    "- If \\( p < 0.05 \\): We reject the null hypothesis and suggest that STA130 students can discern the order of milk and tea with greater than random chance.\n",
    "- If \\( p \\geq 0.05 \\): We fail to reject the null hypothesis, implying that any correct identifications may well be due to random guessing.\n",
    "\n",
    "---\n",
    "\n",
    "This structured report covers all necessary aspects of the experiment and should meet the outlined requirements. Make sure to insert the actual p-value obtained from your simulation code and any relevant visualizations to enhance clarity and presentation. If you have any further questions or need assistance with specific sections, feel free to ask!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74d5bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e82349a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Ethical Professionalism Considerations in Hypothesis Testing and P-values\n",
    "\n",
    "1. **Hypothesis Testing is Not a Mathematical Proof**  \n",
    "   - **Explanation**: Hypothesis testing is inherently probabilistic and does not provide absolute conclusions. Instead, it offers a way to assess evidence against a null hypothesis based on sample data. A p-value reflects the strength of evidence against the null hypothesis, not a definitive proof of its falsity or truth.\n",
    "\n",
    "2. **Evidence Against the Null Hypothesis**  \n",
    "   - **Rejecting the Null Hypothesis**: When we reject the null hypothesis with a p-value of XYZ, it indicates that the evidence we have (from our sample data) is strong enough to suggest that the null hypothesis is unlikely to be true. However, this does not prove it false.  \n",
    "   - **Failing to Reject the Null Hypothesis**: When we fail to reject the null hypothesis with a p-value of XYZ, it implies that we do not have sufficient evidence to claim the null hypothesis is false. It does not mean that the null hypothesis is true, only that our sample did not provide compelling evidence against it.\n",
    "\n",
    "3. **Misleading Conclusions from P-values**  \n",
    "   - **Non-Significant Results**: A \"non-significant result\" does not equate to \"no effect.\" This misconception can arise from inadequate sample size or Type II errors (failing to detect a true effect). Thus, a non-significant result might simply indicate insufficient evidence rather than the absence of an effect.  \n",
    "   - **Significant Results and Type I Errors**: A \"significant result\" might suggest that we have found evidence against the null hypothesis, but this could also be a Type I error (wrongly rejecting a true null hypothesis). Therefore, it is crucial to interpret p-values with caution and context.\n",
    "\n",
    "4. **Importance of Interpreting P-values Using a Clear Table**  \n",
    "   - The provided evidence table helps contextualize the p-value results, providing a clearer understanding of what a given p-value signifies concerning the null hypothesis.\n",
    "\n",
    "5. **Assumptions Underlying P-values**  \n",
    "   - P-values are based on specific assumptions related to the null hypothesis, such as distributional assumptions and random sampling. These assumptions can impact the validity of the conclusions drawn from hypothesis tests.\n",
    "\n",
    "6. **Risks of Overgeneralization**  \n",
    "   - Drawing broad conclusions based on a specific test can lead to overgeneralization errors. For instance, rejecting a null hypothesis regarding the correlation between rain and pizza deliveries does not clarify the nature of that correlation. It might suggest a relationship, but further research is necessary to understand the specifics of that relationship.\n",
    "\n",
    "7. **Confidence Intervals vs. Hypothesis Testing**  \n",
    "   - Confidence intervals provide a range of plausible values for the parameter of interest, offering more informative insights than the binary outcome of hypothesis testing. Hypothesis testing may lead to continuous refinement of hypotheses without identifying plausible values directly. Confidence intervals can more effectively inform us about the nature of the parameter in question.\n",
    "\n",
    "In summary, while p-values and hypothesis testing are valuable tools in statistical analysis, it is crucial to interpret them with caution, understanding their limitations and the context in which they are applied. Clear communication of statistical findings and awareness of ethical responsibilities in data analysis are essential for maintaining professionalism and integrity in the field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03c4153",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c771a00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
