{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4e34a38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stay Wins: 33538 out of 100000 (33.54%)\n",
      "Switch Wins: 66462 out of 100000 (66.46%)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def monty_hall_simulation(reps=100000):\n",
    "    switch_wins = 0\n",
    "    stay_wins = 0\n",
    "\n",
    "    for _ in range(reps):\n",
    "        all_doors = [1, 2, 3]\n",
    "        winning_door = np.random.choice(all_doors)  # Randomly choose the winning door\n",
    "        player_choice = np.random.choice(all_doors)  # Randomly choose the player's initial door\n",
    "\n",
    "        # Reveal a goat door\n",
    "        doors_remaining = [door for door in all_doors if door != player_choice and door != winning_door]\n",
    "        revealed_door = np.random.choice(doors_remaining)\n",
    "\n",
    "        # Determine the door to switch to\n",
    "        switch_choice = [door for door in all_doors if door != player_choice and door != revealed_door][0]\n",
    "\n",
    "        # Check wins for both strategies\n",
    "        if player_choice == winning_door:\n",
    "            stay_wins += 1\n",
    "        if switch_choice == winning_door:\n",
    "            switch_wins += 1\n",
    "\n",
    "    return stay_wins, switch_wins\n",
    "\n",
    "# Run the simulation\n",
    "stay_wins, switch_wins = monty_hall_simulation()\n",
    "\n",
    "# Output the results\n",
    "total_reps = stay_wins + switch_wins\n",
    "print(f\"Stay Wins: {stay_wins} out of {total_reps} ({stay_wins / total_reps * 100:.2f}%)\")\n",
    "print(f\"Switch Wins: {switch_wins} out of {total_reps} ({switch_wins / total_reps * 100:.2f}%)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8cb3389",
   "metadata": {},
   "source": [
    "question 1\n",
    "\n",
    "Explanation\n",
    "Setup:\n",
    "reps: Number of simulations to run.\n",
    "all_doors: List representing the doors.\n",
    "winning_door: Randomly chosen door with the prize.\n",
    "player_choice: Randomly chosen door by the player.\n",
    "Reveal a Door:\n",
    "The code creates a list of remaining doors (those that are not the player's choice and not the winning door) and randomly reveals one.\n",
    "Switch Choice:\n",
    "It determines the door to switch to, which is the only door left after revealing a goat.\n",
    "Count Wins:\n",
    "It counts how many times the player wins when staying and when switching.\n",
    "Results\n",
    "After running the simulation, you’ll see the number of wins for both strategies, demonstrating that switching typically results in a higher probability of winning the car.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a57ae6c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stay Wins: 33558 out of 100000 (33.56%)\n",
      "Switch Wins: 66442 out of 100000 (66.44%)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def monty_hall_simulation(reps=100000):\n",
    "    stay_wins = 0\n",
    "    switch_wins = 0\n",
    "\n",
    "    for _ in range(reps):\n",
    "        # Randomly assign winning door and player's choice\n",
    "        winning_door = np.random.randint(1, 4)  # Winning door: 1, 2, or 3\n",
    "        player_choice = np.random.randint(1, 4)  # Player's initial choice: 1, 2, or 3\n",
    "\n",
    "        # Reveal a goat door\n",
    "        doors = [1, 2, 3]\n",
    "        doors.remove(player_choice)  # Remove player's choice\n",
    "        if winning_door in doors:\n",
    "            doors.remove(winning_door)  # Remove the winning door if it's in the remaining doors\n",
    "        revealed_door = doors[0]  # The door that gets revealed\n",
    "\n",
    "        # Determine switch choice\n",
    "        switch_choice = [door for door in [1, 2, 3] if door != player_choice and door != revealed_door][0]\n",
    "\n",
    "        # Count wins for staying and switching\n",
    "        if player_choice == winning_door:\n",
    "            stay_wins += 1\n",
    "        if switch_choice == winning_door:\n",
    "            switch_wins += 1\n",
    "\n",
    "    return stay_wins, switch_wins\n",
    "\n",
    "# Run the simulation\n",
    "stay_wins, switch_wins = monty_hall_simulation()\n",
    "\n",
    "# Output the results\n",
    "total_reps = stay_wins + switch_wins\n",
    "print(f\"Stay Wins: {stay_wins} out of {total_reps} ({stay_wins / total_reps * 100:.2f}%)\")\n",
    "print(f\"Switch Wins: {switch_wins} out of {total_reps} ({switch_wins / total_reps * 100:.2f}%)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbcaa575",
   "metadata": {},
   "source": [
    "question 2 \n",
    "\n",
    "Key Improvements\n",
    "Simplified Door Handling:\n",
    "Instead of creating a list of remaining doors, we directly manipulate the list, making it easier to understand which doors are involved.\n",
    "Clearer Logic Flow:\n",
    "The logic for revealing a goat door and determining the switch choice is straightforward. This clarity helps in explaining each step.\n",
    "Direct Random Integer Generation:\n",
    "Using np.random.randint(1, 4) simplifies the random door selection process, removing the need for additional lists.\n",
    "Maintained Win Counting:\n",
    "The win counting remains the same but is integrated more seamlessly into the flow.\n",
    "Explanation\n",
    "The code simulates multiple rounds of the game, randomly determining the winning door and the player’s choice.\n",
    "It reveals a goat door based on the remaining doors and counts wins for both the stay and switch strategies.\n",
    "Finally, it prints the results, showing how often each strategy wins.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "608196de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stay Wins: 33440 out of 100000 (33.44%)\n",
      "Switch Wins: 66560 out of 100000 (66.56%)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np  # Import NumPy for random number generation\n",
    "\n",
    "def monty_hall_simulation(reps=100000):\n",
    "    stay_wins = 0  # Initialize counter for wins when staying\n",
    "    switch_wins = 0  # Initialize counter for wins when switching\n",
    "\n",
    "    for _ in range(reps):  # Loop for the number of repetitions\n",
    "        # Randomly assign the winning door and the player's initial choice\n",
    "        winning_door = np.random.randint(1, 4)  # Winning door: randomly 1, 2, or 3\n",
    "        player_choice = np.random.randint(1, 4)  # Player's choice: randomly 1, 2, or 3\n",
    "\n",
    "        # Prepare to reveal a goat door\n",
    "        doors = [1, 2, 3]  # List of all doors\n",
    "        doors.remove(player_choice)  # Remove the player's chosen door from the list\n",
    "\n",
    "        # If the winning door is among the remaining doors, remove it to reveal a goat\n",
    "        if winning_door in doors:\n",
    "            doors.remove(winning_door)  # Remove the winning door if it's one of the remaining doors\n",
    "        revealed_door = doors[0]  # The remaining door is the one that gets revealed (goat)\n",
    "\n",
    "        # Determine the door to switch to\n",
    "        switch_choice = [door for door in [1, 2, 3] if door != player_choice and door != revealed_door][0]\n",
    "\n",
    "        # Count wins based on the player's final choice\n",
    "        if player_choice == winning_door:  # Check if staying wins\n",
    "            stay_wins += 1  # Increment stay wins counter\n",
    "        if switch_choice == winning_door:  # Check if switching wins\n",
    "            switch_wins += 1  # Increment switch wins counter\n",
    "\n",
    "    return stay_wins, switch_wins  # Return the counts of wins for both strategies\n",
    "\n",
    "# Run the simulation\n",
    "stay_wins, switch_wins = monty_hall_simulation()\n",
    "\n",
    "# Calculate total repetitions for output\n",
    "total_reps = stay_wins + switch_wins\n",
    "# Print the results: number of wins for staying and switching, with percentages\n",
    "print(f\"Stay Wins: {stay_wins} out of {total_reps} ({stay_wins / total_reps * 100:.2f}%)\")\n",
    "print(f\"Switch Wins: {switch_wins} out of {total_reps} ({switch_wins / total_reps * 100:.2f}%)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aebece08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0689ae31",
   "metadata": {},
   "source": [
    "question 4\n",
    "\n",
    "Overview of Markov Chains\n",
    "Markov chains are mathematical systems that undergo transitions from one state to another on a state space. In the context of text generation, a Markov chain can generate sentences based on the probabilities of word sequences. It looks at the current state (or word) and selects the next state (or word) based on predefined probabilities derived from a training corpus.\n",
    "\n",
    "Creating a Markovian ChatBot\n",
    "Here’s a basic version of a Markovian ChatBot in Python. You can use this as a starting point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f346095",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'kingdoms'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 32\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# Interact with the ChatBot\u001b[39;00m\n\u001b[1;32m     31\u001b[0m user_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mknight\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 32\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mchatbot\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChatBot:\u001b[39m\u001b[38;5;124m\"\u001b[39m, response)\n",
      "Cell \u001b[0;32mIn[1], line 22\u001b[0m, in \u001b[0;36mMarkovianChatBot.generate_response\u001b[0;34m(self, input_word, length)\u001b[0m\n\u001b[1;32m     20\u001b[0m response \u001b[38;5;241m=\u001b[39m [input_word]\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(length \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m---> 22\u001b[0m     next_words \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchain\u001b[49m\u001b[43m[\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     23\u001b[0m     response\u001b[38;5;241m.\u001b[39mappend(random\u001b[38;5;241m.\u001b[39mchoice(next_words))\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(response)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'kingdoms'"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import re\n",
    "\n",
    "class MarkovianChatBot:\n",
    "    def __init__(self, corpus):\n",
    "        self.chain = self.build_chain(corpus)\n",
    "\n",
    "    def build_chain(self, corpus):\n",
    "        words = re.findall(r'\\w+', corpus)\n",
    "        chain = {}\n",
    "        for i in range(len(words) - 1):\n",
    "            if words[i] not in chain:\n",
    "                chain[words[i]] = []\n",
    "            chain[words[i]].append(words[i + 1])\n",
    "        return chain\n",
    "\n",
    "    def generate_response(self, input_word, length=10):\n",
    "        if input_word not in self.chain:\n",
    "            return \"I don't know that word.\"\n",
    "        response = [input_word]\n",
    "        for _ in range(length - 1):\n",
    "            next_words = self.chain[response[-1]]\n",
    "            response.append(random.choice(next_words))\n",
    "        return ' '.join(response)\n",
    "\n",
    "# Example usage\n",
    "corpus = \"Once upon a time, there was a brave knight. The knight fought dragons and saved kingdoms.\"\n",
    "chatbot = MarkovianChatBot(corpus)\n",
    "\n",
    "# Interact with the ChatBot\n",
    "user_input = \"knight\"\n",
    "response = chatbot.generate_response(user_input)\n",
    "print(\"ChatBot:\", response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0588f238",
   "metadata": {},
   "source": [
    "How It Works\n",
    "Corpus: The corpus is a string of text that the bot uses to learn word associations.\n",
    "Build Chain: The build_chain function creates a dictionary where each word points to a list of words that can follow it.\n",
    "Generate Response: Given an input word, the bot generates a response by choosing the next word based on the probabilities derived from the corpus.\n",
    "Training Your ChatBot\n",
    "You mentioned training the ChatBot using stories with different characters. You can replace the corpus variable with any collection of stories you like to see how it generates different outputs based on that text.\n",
    "\n",
    "Next Steps\n",
    "Run the Code: You can run the code in your local Jupyter environment to see how it works.\n",
    "Experiment: Change the corpus or the input word to see how the ChatBot responds.\n",
    "Summarize: After your session, summarize your findings and interactions, and be sure to save the chat log."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994db8d0",
   "metadata": {},
   "source": [
    "question 5\n",
    "\n",
    "Provide the First Extension "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d716271",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharacterMarkovianChatBot:\n",
    "    def __init__(self, corpus):\n",
    "        self.chains = {}\n",
    "        self.build_chain(corpus)\n",
    "\n",
    "    def build_chain(self, corpus):\n",
    "        for line in corpus.splitlines():\n",
    "            character, text = line.split(\":\", 1)  # Expected format \"Character: Text\"\n",
    "            words = re.findall(r'\\w+', text)\n",
    "            if character not in self.chains:\n",
    "                self.chains[character] = {}\n",
    "            for i in range(len(words) - 1):\n",
    "                if words[i] not in self.chains[character]:\n",
    "                    self.chains[character][words[i]] = []\n",
    "                self.chains[character][words[i]].append(words[i + 1])\n",
    "\n",
    "    def generate_response(self, character, input_word, length=10):\n",
    "        if character not in self.chains or input_word not in self.chains[character]:\n",
    "            return \"I don't know that character or word.\"\n",
    "        response = [input_word]\n",
    "        for _ in range(length - 1):\n",
    "            next_words = self.chains[character][response[-1]]\n",
    "            response.append(random.choice(next_words))\n",
    "        return ' '.join(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ff861a",
   "metadata": {},
   "source": [
    "How does the first piece of extension code handle role-specific text? Can you explain what it does?\n",
    "\n",
    "Explanation of Functionality\n",
    "Initialization (__init__ method):\n",
    "self.chains is a dictionary that will store the Markov chains for each character.\n",
    "The build_chain method is called to construct these chains.\n",
    "Building the Chain (build_chain method):\n",
    "corpus is a string containing textual data, with each line representing a character and their corresponding text.\n",
    "The splitlines() method divides the text into multiple lines.\n",
    "Each line is split by the colon : to separate the character from their text.\n",
    "Extracting Words:\n",
    "The regular expression re.findall(r'\\w+', text) is used to extract all words from the text.\n",
    "Creating Character-Specific Chains:\n",
    "If a character is not already in self.chains, a new dictionary is initialized for that character.\n",
    "The code iterates through the extracted words to build the Markov chain for each character:\n",
    "For each word, it checks if the word is already in the character's chain. If not, it creates an empty list.\n",
    "The word following the current word is added to the list corresponding to that word, forming a chain.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "623b103f",
   "metadata": {},
   "source": [
    "Second Extension: Using Bigrams:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d20d4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BigramMarkovianChatBot:\n",
    "    def __init__(self, corpus):\n",
    "        self.chain = {}\n",
    "        self.build_chain(corpus)\n",
    "\n",
    "    def build_chain(self, corpus):\n",
    "        words = re.findall(r'\\w+', corpus)\n",
    "        for i in range(len(words) - 1):\n",
    "            bigram = (words[i], words[i + 1])\n",
    "            if bigram not in self.chain:\n",
    "                self.chain[bigram] = []\n",
    "            if i < len(words) - 2:  # Ensure there’s a next word\n",
    "                self.chain[bigram].append(words[i + 2])\n",
    "\n",
    "    def generate_response(self, input_word1, input_word2, length=10):\n",
    "        bigram = (input_word1, input_word2)\n",
    "        if bigram not in self.chain:\n",
    "            return \"I don't know that bigram.\"\n",
    "        response = list(bigram)\n",
    "        for _ in range(length - 2):  # Already have 2 words\n",
    "            next_words = self.chain[bigram]\n",
    "            next_word = random.choice(next_words)\n",
    "            response.append(next_word)\n",
    "            bigram = (input_word2, next_word)  # Update the bigram\n",
    "            input_word2 = next_word  # Update for the next iteration\n",
    "        return ' '.join(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63021a14",
   "metadata": {},
   "source": [
    "How does this bigram extension change the text generation? Can you explain its functionality?\n",
    "Use of Bigrams:\n",
    "Unlike the original Markov chain that relied on a single previous word, the bigram extension considers pairs of consecutive words. This allows the model to capture more contextual information from the text.\n",
    "For example, it looks at the relationship between \"happy birthday\" rather than just \"birthday,\" leading to more coherent and contextually appropriate responses.\n",
    "Building the Chain:\n",
    "The build_chain method constructs a mapping of bigrams (pairs of words) to subsequent words. Each bigram is stored as a key in the dictionary, and the list of possible next words follows that bigram.\n",
    "This creates a richer dataset for the ChatBot to draw from, as it learns how words typically follow each other in the text.\n",
    "Generating Responses:\n",
    "The generate_response method starts with a provided bigram and uses it as a seed to generate the output.\n",
    "It randomly selects the next word based on the existing bigram and updates the bigram for subsequent iterations, allowing for more varied and contextually relevant responses.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b100a793",
   "metadata": {},
   "source": [
    "Session 2: Introducing the Original Code and Final Extension\n",
    "Start a New Session:\n",
    "First, show the original Markovian ChatBot code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2531d4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MarkovianChatBot:\n",
    "    def __init__(self, corpus):\n",
    "        self.chain = self.build_chain(corpus)\n",
    "\n",
    "    def build_chain(self, corpus):\n",
    "        words = re.findall(r'\\w+', corpus)\n",
    "        chain = {}\n",
    "        for i in range(len(words) - 1):\n",
    "            if words[i] not in chain:\n",
    "                chain[words[i]] = []\n",
    "            chain[words[i]].append(words[i + 1])\n",
    "        return chain\n",
    "\n",
    "    def generate_response(self, input_word, length=10):\n",
    "        if input_word not in self.chain:\n",
    "            return \"I don't know that word.\"\n",
    "        response = [input_word]\n",
    "        for _ in range(length - 1):\n",
    "            next_words = self.chain[response[-1]]\n",
    "            response.append(random.choice(next_words))\n",
    "        return ' '.join(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63dfdc95",
   "metadata": {},
   "source": [
    "Provide the Final Extension (Combining Character-Specific Chains with Bigrams):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399dabff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CombinedMarkovianChatBot:\n",
    "    def __init__(self, corpus):\n",
    "        self.chains = {}\n",
    "        self.build_chain(corpus)\n",
    "\n",
    "    def build_chain(self, corpus):\n",
    "        for line in corpus.splitlines():\n",
    "            character, text = line.split(\":\", 1)\n",
    "            words = re.findall(r'\\w+', text)\n",
    "            if character not in self.chains:\n",
    "                self.chains[character] = {}\n",
    "            for i in range(len(words) - 2):\n",
    "                bigram = (words[i], words[i + 1])\n",
    "                if bigram not in self.chains[character]:\n",
    "                    self.chains[character][bigram] = []\n",
    "                self.chains[character][bigram].append(words[i + 2])\n",
    "\n",
    "    def generate_response(self, character, input_word1, input_word2, length=10):\n",
    "        bigram = (input_word1, input_word2)\n",
    "        if character not in self.chains or bigram not in self.chains[character]:\n",
    "            return \"I don't know that character or bigram.\"\n",
    "        response = list(bigram)\n",
    "        for _ in range(length - 2):\n",
    "            next_words = self.chains[character][bigram]\n",
    "            next_word = random.choice(next_words)\n",
    "            response.append(next_word)\n",
    "            bigram = (input_word2, next_word)\n",
    "            input_word2 = next_word\n",
    "        return ' '.join(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7af628",
   "metadata": {},
   "source": [
    "How does this final extension work? What advantages does it provide compared to the original code?\n",
    "How It Works\n",
    "Character-Specific Chains:\n",
    "Each character has its own Markov chain. The build_chain method constructs these chains from the provided corpus, where each line contains a character and their corresponding dialogue.\n",
    "This means that responses can vary significantly based on the character, allowing for more personality in the text generation.\n",
    "Bigrams for Context:\n",
    "The code uses bigrams (pairs of consecutive words) to create relationships between words. This provides context beyond just the last word, leading to more coherent and contextually appropriate outputs.\n",
    "The model captures the flow of dialogue better, as it considers how words are likely to follow each other in the character's speech.\n",
    "Response Generation:\n",
    "The generate_response method starts with a specified bigram and character, checking if the character and bigram exist in the chain.\n",
    "It builds the response iteratively, updating the bigram and selecting the next word based on the character's specific context.\n",
    "Advantages Over the Original Code\n",
    "Increased Coherence:\n",
    "By using bigrams, the text generated is generally more coherent and contextually relevant compared to a model that relies solely on the last word.\n",
    "Character Distinction:\n",
    "The model can generate responses that are distinct to each character, allowing for a richer and more varied dialogue experience.\n",
    "Improved Contextual Awareness:\n",
    "The bigram approach provides greater contextual awareness, allowing the ChatBot to produce outputs that make more sense within the context of the dialogue.\n",
    "Enhanced Flexibility:\n",
    "The combination of character-specific chains with bigrams offers more flexibility in generating unique responses, making the interactions feel more natural and engaging.\n",
    "Summary\n",
    "The final extension enhances the ChatBot's ability to generate personalized, coherent, and contextually appropriate responses by integrating character-specific behavior with bigram dependencies. This results in a more sophisticated and engaging conversational experience compared to the original single-word dependency model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "707bab78",
   "metadata": {},
   "source": [
    "6.\n",
    "\n",
    "a）Speed and Helpfulness:\n",
    "Monte Hall Problem: The ChatBot was quite prompt in addressing my questions regarding the Monte Hall problem. It quickly explained the mechanics of the problem, helping me grasp the counterintuitive aspects of switching doors versus sticking with the original choice. The explanations were clear and concise, allowing me to understand the probability concepts behind the problem without excessive back-and-forth.\n",
    "Markovian ChatBot Code: When discussing the Markovian ChatBot code, the ChatBot effectively broke down the code components, explaining how each part contributed to the overall functionality. It quickly clarified how character-specific chains and bigram dependencies worked, which was crucial for understanding the final extension of the code. Overall, the ChatBot provided timely and relevant information that enhanced my comprehension.\n",
    "\n",
    "b）Frustration or Helpfulness:\n",
    "I did not experience significant frustration while interacting with the ChatBot. However, there were moments when the ChatBot's responses could have been more detailed, especially when I was probing deeper into the intricacies of the code. Occasionally, the ChatBot required prompting or specific questions to provide the depth of explanation I was seeking. For example, when I asked about the implications of using bigrams, I had to guide the conversation a bit to get more nuanced insights. Overall, while there were minor gaps, the interactions were largely constructive.\n",
    "\n",
    "c）Overall Assessment of ChatBots:\n",
    "My experiences with ChatBots have generally been positive, particularly in understanding coding concepts and troubleshooting. They serve as valuable tools for clarifying doubts and providing step-by-step explanations of complex topics. The ability to ask specific questions and receive immediate feedback is a significant advantage, especially when working on coding assignments.\n",
    "However, I recognize that ChatBots may have limitations in their depth of understanding, which can sometimes lead to incomplete answers. They excel at addressing straightforward queries and providing explanations, but may struggle with more complex, nuanced topics without specific prompts.\n",
    "In conclusion, while ChatBots are not a replacement for comprehensive learning resources or expert advice, they are effective supplementary tools that can enhance understanding and aid in problem-solving. They can be particularly useful for quickly clarifying concepts and debugging code, making them a valuable asset in the learning process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8045240",
   "metadata": {},
   "source": [
    "7.\n",
    "\n",
    "Increased Confidence:\n",
    "Initially, I was skeptical about how effective AI tools could be in helping me understand complex topics. However, my interactions with ChatBots have boosted my confidence in tackling difficult concepts. The immediate availability of explanations and examples has made it easier for me to grasp challenging material.\n",
    "\n",
    "Enhanced Learning Experience:\n",
    "I’ve come to appreciate how AI tools can provide tailored support. The ability to ask specific questions and receive detailed, step-by-step explanations has transformed my learning experience. This interactive approach has helped me stay engaged and motivated, making the process feel less daunting.\n",
    "\n",
    "Efficiency in Problem-Solving:\n",
    "ChatBots have proven to be invaluable for troubleshooting coding issues and clarifying statistical concepts. The quick responses save time and help me focus on understanding rather than getting stuck on problems. This efficiency allows me to progress more rapidly in my learning journey.\n",
    "\n",
    "Supplementary Role:\n",
    "While I recognize the strengths of AI tools, I've also learned that they are most effective when used as a supplement to traditional learning methods. They provide quick answers and insights but cannot replace in-depth understanding gained from textbooks, lectures, or hands-on practice. The best results come from combining AI assistance with comprehensive study techniques.\n",
    "\n",
    "Growing Acceptance of AI:\n",
    "My initial hesitance about relying on AI for learning has shifted to a more accepting viewpoint. I now see AI as a collaborative partner in my education, helping to clarify doubts and enhance my understanding. The tools have become an integral part of my study routine.\n",
    "\n",
    "Openness to Future Applications:\n",
    "As I continue my studies, I am excited about the potential future applications of AI in education. The ability of these tools to evolve and adapt to individual learning styles could lead to even more personalized learning experiences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb75ab57",
   "metadata": {},
   "source": [
    "9.\n",
    "somewhat"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
